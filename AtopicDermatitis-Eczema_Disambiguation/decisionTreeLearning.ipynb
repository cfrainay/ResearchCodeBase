{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eczema and Atopic dermatitis articles classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda doc: doc.lower().split(\" \")\n",
    "dictLabel = {}\n",
    "labelId = 0\n",
    "path = \"./data/cleaned/\"\n",
    "\n",
    "labels = [\"eczema\", \"AD\"]\n",
    "labelIds = [0,1]\n",
    "XRawList = []\n",
    "yList = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for creating balanced subsampled dataset\n",
    "\n",
    "As the documents indexed under _dermatitis, atopic_ outnumber those indexed under _eczema_, train set need to be balanced. We use down sampling, randomly selecting a number of documents from the majority class (_dermatitis, atopic_) equals to the number of documents from the minority class. As the training set will be different at each run, results might slightly vary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_subsample(x,y,subsample_size=1.0):\n",
    "\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "        #if this_xs.shape[0] > use_elems:\n",
    "            np.random.shuffle(this_xs)\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = np.concatenate(xs)\n",
    "    ys = np.concatenate(ys)\n",
    "\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import documents\n",
    "\n",
    "Documents correspond to preprocessed title and abstract retrieved from pubmed. Preprocessing include removal of stop words and convertion of words to lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in os.listdir(path) :\n",
    "\n",
    "    if \"Store\" not in label and \"ipynb_checkpoints\" not in label: \n",
    "\n",
    "        for txt in os.listdir(path+\"/\"+label):\n",
    "            if \"ipynb_checkpoints\" not in txt :\n",
    "                with open(path+\"/\"+label+\"/\"+txt) as finput :\n",
    "                    XRawList.append(finput.read())\n",
    "                    if \"derma\" in label : \n",
    "                        yList.append(1)\n",
    "                    else :\n",
    "                        yList.append(0)\n",
    "\n",
    "\n",
    "y = np.asarray(yList)\n",
    "XRaw = np.asarray(XRawList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert documents to feature vectors\n",
    "\n",
    "Documents are represented as binary vectors, for which each position correpond to a word, and the value correspond to its presence or absence in the title or abstract. Each document has a known class definied by its MeSH indexing term in PubMed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize documents\n",
    "# -- min_df : minimum frequency required to consider a word. Allow to reduce dimensions.\n",
    "# -- ngram_range : allow to consider ngrams (contiguous sequence of words) as feature. When set to [1,1], \n",
    "#    consider only single words for a simplier model.\n",
    "# -- binary : consider presence/absence of a word if true, number of occurences otherwise\n",
    "sklearn_count = CountVectorizer(min_df=10, tokenizer=tokenize, ngram_range=[1,1], binary=True)\n",
    "X = sklearn_count.fit_transform(XRaw)\n",
    "# convert to dense matrix\n",
    "X = X.todense()\n",
    "\n",
    "# save vocabulary to translate features key back to words\n",
    "inv_map = {v: k for k, v in sklearn_count.vocabulary_.items()}\n",
    "feat_names = []\n",
    "with open(\"dict.txt\", \"w\") as fout : \n",
    "    for key in sorted(inv_map.keys()) : \n",
    "        fout.write(str(key)+\"\\t\"+inv_map[key]+\"\\n\")\n",
    "        feat_names.append(inv_map[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Decision Tree\n",
    "\n",
    "Build Decision Tree for _eczema_ and _dermatitis, atopic_ indexing classification, using CART algorithm with Gini impurity as split criterion. Maximum tree depth set to 6 and minimum proportion of total sample in a leaf set to 1%, in order to avoid overfitting and keep a simple model for ease of interpretation.\n",
    "The test set represent 20% of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Randomly split dataset into train et test set\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, stratify=y, random_state = 42)\n",
    "\n",
    "# Balance trainset to avoid bias toward majority class \n",
    "X_train, y_train =  balanced_subsample(X,y,subsample_size=1.0)\n",
    "\n",
    "# Perform decision tree learning\n",
    "# -- criterion = Measure of the quality of a split, used to decide at each step \n",
    "#    which feature is best to split the data\n",
    "# -- max_depth = Maximum depth of the tree.\n",
    "# -- min_samples_leaf = The minimum proportion of total sample in a leaf. \n",
    "#    Below this value, no further split are performed. Prevent over-fitting\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth=6, min_samples_leaf=0.01)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tree visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tree vizualisation\n",
    "with open('./viz/tree.dot', \"w\") as f : \n",
    "    f = tree.export_graphviz(clf,out_file=f, \n",
    "                             proportion=True, \n",
    "                             feature_names=feat_names, \n",
    "                             class_names=labels, \n",
    "                             filled=True, \n",
    "                             rounded=True, \n",
    "                             rotate=True)\n",
    "\n",
    "with open('./viz/tree.dot', \"r\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Performance evaluated using F1 score, accuracy, specificity and ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# apply classification model to test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred,target_names=labels))\n",
    "\n",
    "# compute f1 score\n",
    "score = f1_score(y_test, y_pred, average='weighted') \n",
    "print(\"F1-score = \",(score*100))\n",
    "\n",
    "# compute ROC curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_prob = clf.predict_proba(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1],pos_label=1)\n",
    "plt.plot(fpr, tpr,'r-')\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "# print AUC score\n",
    "print(\"ROC AUC =\",roc_auc_score(y_test, y_prob[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
